---
title: "London Cycle Hires and Weather"
output: html_document
---
```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(ggplot2)
library(reshape2)
library(dplyr)
library(lubridate)
```

```{r, echo=FALSE}
# First load the weather.

weather <- read.csv('weather.csv')
names(weather) <- c('date', 't.max', 't', 't.min', 'dew.max', 'dew', 'dew.min',
                    'hum.max', 'hum', 'hum.min', 'pres.max', 'pres', 
                    'pres.min', 'vis.max', 'vis', 'vis.min', 'wind.max',
                    'wind', 'gust', 'precip.mm', 'cloud', 'events', 'wind.dir')

# Remove columns that I'm not going to be looking at
weather <- subset(weather, select=c('date', 't.max', 't', 't.min', 'wind.max',
                                    'wind', 'gust', 'precip.mm', 'events'))

weather$date <- as.Date(weather$date)

# The events are Fog, Rain, Snow, and Thunderstorm. Only rain and fog have 
# enough days to be worth looking at (even fog is marginal, at 36).
weather$rain <- grepl('Rain', weather$events)
weather$fog <- grepl('Fog', weather$events)

# I'm going to need times with no dates attached. The way to do that seems to
# be to have datetimes with a constant date.
as.time <- function (ct) {
  return(as.POSIXct(as.numeric(ct) %% 86400, origin = "2000-01-01"))
}

# It's easier to wrangle the bike files separately and then put them together
# than to put them together before wrangling, because of the prev.* and d.*
# columns.

read.bikes <- function (fname) {
  bikes <- read.csv(fname)

  # Remove columns we won't be looking at. id/lat/long are constant within each
  # file. The others are constant over the whole dataset.
  bikes$id <- NULL
  bikes$lat <- NULL
  bikes$long <- NULL
  bikes$installed <- NULL
  bikes$locked <- NULL
  bikes$temporary <- NULL

  # Rename and restructure
  names(bikes) <- c('updated', 'name', 'num.bikes', 'num.spaces')
  bikes$updated <- as.POSIXct(strptime(bikes$updated, "%Y-%m-%dT%H:%M:%S%z"))
  
  # Add columns derived from existing ones.
  bikes$updated.time <- as.time(bikes$updated)
  bikes$updated.date <- as.Date(bikes$updated)
  bikes$num.docks <- with(bikes, num.bikes+num.spaces)
  bikes$weekday <- wday(bikes$updated.date, label=T)
  bikes$is.weekday <- wday(bikes$updated.date) %in% seq(2,6)

  # Add columns for prev and diff between updates. I feel like there should be
  # a better way to do this, but I haven't found it. (Time series don't seem to
  # work very well.) Only add ones I actually use.
  bikes$prev.updated <- c(as.POSIXct(NA), head(bikes$updated, -1))
  bikes$prev.updated.time <- as.time(bikes$prev.updated)
  bikes$prev.updated.date <- as.Date(bikes$prev.updated)
  bikes$prev.num.bikes <- c(NA, head(bikes$num.bikes, -1))
  bikes$prev.num.docks <- c(NA, head(bikes$num.docks, -1))

  bikes$d.updated <- with(bikes, as.numeric(updated - prev.updated))
  bikes$d.num.bikes <- with(bikes, num.bikes - prev.num.bikes)
  
  return(bikes)
}

bikes <- rbind(read.bikes('bikes-sp.csv'),
               read.bikes('bikes-hh.csv'),
               read.bikes('bikes-bp.csv'),
               read.bikes('bikes-es.csv'))

# The subset is justified later on.
bikes.all <- merge(x=bikes, y=weather, by.x='updated.date', by.y='date')
bikes <- subset(bikes.all, d.updated <= 15)
```

```{r, echo=FALSE}
# I also want to look at the number of bikes available at specific times. Since 
# I only have snapshots, I'm going to take the first observation after that 
# time on any given day. Here's a function that lets me do that. It takes a 
# time in format '0930', and return a boolean vector to select the appropriate 
# entries from bikes.
at.time <- function(time) {
  # prev.updated.time < time <= updated.time is the obvious test. But it fails
  # around day boundaries, so we also check whether the date changed.
  time <- as.time(as.POSIXct(time, format='%H%M'))
  with(bikes, (prev.updated.time < time | prev.updated.date < updated.date) &
              time <= updated.time)
}
```

# Univariate plots section

Temperature:

```{r}
temps <- melt(weather, id.vars='date', measure.vars=c('t.min','t','t.max'))
ggplot(temps, aes(x=variable, y=value)) + geom_boxplot()
ggplot(temps, aes(x=value, fill=variable)) + geom_density(alpha=0.3)
```

Rainfall:

```{r}
ggplot(weather, aes(x=precip.mm)) + geom_histogram(binwidth=0.2)
```

Wind:

```{r, warning=FALSE}
winds <- melt(weather, id.vars='date',
              measure.vars=c('wind','wind.max','gust'))
ggplot(winds, aes(x=variable, y=value)) + geom_boxplot()
ggplot(winds, aes(x=value, fill=variable)) + geom_density(alpha=0.3)
```

Time between updates:

```{r}
ggplot(bikes.all, aes(x=d.updated, y=..count..+1)) + 
  geom_histogram(binwidth=20) +
  scale_y_log10()
```

A few outliers. Let's zoom in on them.

```{r}
ggplot(bikes.all[bikes.all$d.updated >= 5000,], aes(x=d.updated)) +
  geom_histogram(binwidth=5)
bikes[bikes.all$d.updated >= 5000, c('name', 'prev.updated', 'updated')]
```

and on the lower ones:

```{r}
ggplot(bikes.all[bikes.all$d.updated < 5000,], 
       aes(x=d.updated, y=..count..+1)) +
  geom_histogram(binwidth=5) +
  scale_y_log10()

bikes.all[bikes.all$d.updated >= 2000 & bikes.all$d.updated < 5000,
          c('name', 'prev.updated', 'updated')]

ggplot(bikes.all[bikes.all$d.updated < 60,], aes(x=d.updated)) + 
  geom_histogram(binwidth=1)
```

Time of update:

```{r}
ggplot(bikes.all, aes(x=updated.time)) + 
  geom_histogram(binwidth=600) +
  scale_x_datetime()
```

# Univariate Analysis

The temperature is a little surprising. I didn't expect the graphs to be bimodal. But we would expect the three measures to have similar shapes, and bimodality could be caused by e.g. an abrupt shift between summer and winter.

There are five instances where the time between updates is approximately ten days. Four of these happened when my collection script broke and I failed to realize it. The other occurred when Southampton Place was taken out of service temporarily.

Then there are a several instances where the time between updates is unusually large, on the order of hours or days. It looks like these happened to all stations simultaneously, suggesting problems with either my collection script or the API, rather than problems with individual locations.

But in the vast majority of cases, updates are approximately ten minutes apart. This encourages me to take a subset of the data (`bikes.all` -> `bikes`), eliminating outliers in future graphs.

All times of day are approximately equally represented, which is good.

# Bivariate Plots Section

Rainfall as measured by `precip.mm` versus as measured by `rain`:

```{r}
ggplot(weather, aes(y=precip.mm, x=rain)) + geom_boxplot()
```

Length of time spent with a given number of active docks:
```{r, warning=FALSE}
ggplot(bikes, aes(x=prev.num.docks, y=d.updated/60/24)) +
  geom_histogram(stat='identity') +
  facet_wrap(~name)
```

Journeys taken on rainy vs. non-rainy days:

```{r, warning=FALSE}
ggplot(group_by(bikes, rain) %>% mutate(count=1/length(rain)),
       aes(x=d.num.bikes, y=count)) + 
  geom_bar(stat='identity') +
  scale_x_discrete() +
  facet_wrap(~rain)

group_by(bikes, rain) %>% summarise(mean(abs(d.num.bikes)))
```

And foggy versus non-foggy days:

```{r, warning=FALSE}
ggplot(group_by(bikes, fog) %>% mutate(count=1/length(fog)),
       aes(x=d.num.bikes, y=count)) + 
  geom_bar(stat='identity') +
  scale_x_discrete() +
  facet_wrap(~fog)

group_by(bikes, fog) %>% summarise(mean(abs(d.num.bikes)))
```

Journeys by weekday:

```{r, warning=FALSE}
ggplot(bikes, aes(x=weekday, y=abs(d.num.bikes))) + 
  geom_bar(stat='identity')
ggplot(bikes, aes(x=weekday, y=num.bikes)) + geom_boxplot()

ggplot(bikes, aes(x=num.bikes/num.docks)) + 
  geom_density() + 
  facet_wrap(~weekday)
```

Number of slots available at 0930, when I'm trying to arrive at work:

```{r}
ggplot(bikes[at.time('0930') & bikes$is.weekday,] %>% 
         group_by(name) %>% 
         mutate(count=1/length(name)),
       aes(x=num.spaces, y=count)) +
  geom_bar(stat='identity',binwidth=1) +
  facet_wrap(~name)
```

And at 0940, in case I'm running late:

```{r}
ggplot(bikes[at.time('0940') & bikes$is.weekday,] %>% 
         group_by(name) %>% 
         mutate(count=1/length(name)),
       aes(x=num.spaces, y=count)) +
  geom_bar(stat='identity',binwidth=1) +
  facet_wrap(~name)
```

# Bivariate Analysis

`rain` and `precip.mm` don't always agree. Sometimes `rain` is false but `precip.mm` is nonzero; and often `rain` is true but `precip.mm` is zero. Neither of those is surprising individually: if `rain` is only counted when the rainfall exceeds a certain threshold, then that threshold could be large (giving false/nonzero) or small (giving true/zero). But the combination suggests that that isn't what's going on, and I don't know what is.

It was common for every station to report less than a full complement of docks. Two stations had a full complement less than half the time. This isn't surprising, since a bike reported as defective will be locked in, using up a slot but not being available for hire.

Slightly over 70% of observations had no bikes added or removed on rainy days, and slightly under 70% on non-rainy days. The mean absolute difference is about 25% higher on non-rainy days. On the other hand, fog makes approximately no difference.

Fewer journeys are taken on weekends. The median number of bikes available doesn't change much throughout the week, but the distribution does. Saturday and Sunday have noticeably different shapes to the others. They have a single peak, while weekdays are somewhat bimodal, with a small peak where the station is full (probably when people are arriving at work).

(Since the stations have different numbers of docks, I did a graph of fullness rather than of number of bikes. The density plot doesn't show peaks exactly at 0 and 1 because of how the window works, but histograms of num.bikes and num.spaces show that that's where they are. It would be difficult to use a histogram for this graph because there's no sensible binwidth.)

If I'm late, I have slightly less chance of finding a docking station, but not much less.

# Multivariate plots 

Correlation between #bikes at each tick:

```{r, warning=FALSE}
ggplot(bikes, aes(x=num.bikes, y=prev.num.bikes, color=name)) + 
  geom_jitter(alpha=0.05)

cor.test(bikes$num.bikes, bikes$prev.num.bikes)
```

Bikes at any given time:

```{r, warning=FALSE}
ggplot(bikes, aes(x=updated.time, y=num.bikes, color=name)) + 
  geom_jitter(alpha=0.05, shape=1) +
  stat_smooth()
```

Bikes depending on rain:

```{r, warning=FALSE}
ggplot(bikes, aes(x=updated.time, y=num.bikes, color=rain)) +
  geom_jitter(alpha=0.05, shape=1) +
  stat_smooth()
```

# Multivariate analysis

There's very strong correlation between the number of bikes at each axis. This is as expected, especially given what we saw about `d.num.bikes` previously. The colors don't show any particular station-dependent trends.

The correlation also looks strong between the number of bikes at each station at any given time. Since they're all close to each other, that's not surprising either. The time is also a big factor, with large numbers of bikes in the stations during office hours, and few numbers in the evening and early morning.

Rain reduces the variance, with fewer bikes during office hours and more outside of them.